# Hardware 

- Raspberry Pi Zero 2W or 4B
- PIR sensor
- Raspberry Pi Camera Module V2
- USB battery
- LED (optional)

![Hardware+software-image](Hardware+software.pdf?raw=true "Title")
 
## Wiring

You can use ``pinout`` command to verify the GPIO pin numbering on the Raspberry Pi.

- **PIR sensor**: connect the OUT pin of the PIR sensor to GPIO17 (this can be configured in the configuration.ini file  under the ``INPUT_PIN`` parameter).
  Additionally, connect the sensor's Ground and DC power pins to the corresponding pins on the Raspberry Pi.
- **Camera module**: Attach the camera module to the Raspberry Pi using the CSI interface. Ensure that camera access is enabled via the ``raspi-config`` tool.
- **LED**: A light-emitting diode (LED) can be used to indicate the camera's operation. The LED will illuminate when the camera is capturing and processing images. 
    Connect the LED to GPIO4 (configurable in the configuration.ini file under the ``OUTPUT_PIN`` parameter) and the Ground pin of the Raspberry Pi.
- **Battery**: The Raspberry Pi platform must be powered by an appropriate power supply.

# Operating System

The prototype was tested on Rasbian GNU/Linux 10 (buster) kernel Linux 6.1.61-v8+ aarch64 32 bits (legacy).
We are working on an enhanced version using Raspberry Pi Operating System (bookworm) aarch64 64 bits.

# Summary of implemented functionalities

- *Main loop*: **Capture a set of images upon PIR activation**, **classify** them into ./OUTPUT/Animal or ./OUTPUT/Blank. **Send an alarm** if classified into  ``TARGET_LABELS`` ('Animal').
- *Logging*: Save a log file and transmit MQTT messages containing relevant information.
- *Night mode*: Disable the system's functionality during nighttime, as determined by analyzing the images collected.
- *Dataset generation*: Capture an image every ``SEC_TEST`` seconds -only when PIR does not detect action- to **build on-device training datasets**, and store in ./DATASET/FRAMES/.
- *Re-training*: re-train the AI (referred to as "re-calibrate") each CALIB_PERIOD=X minutes if necessary:
  - To determine if re-training is needed, capture frames over a 10-second period at the specified FPS and analyze them using a CNN model. If 75% of the
     images are classified under ``TARGET_LABELS`` ('Animal'), initiate re-training.
    - if re-training is not needed, reduce X by half. 
    - If X has been reduced 4 consecutive times, reset it to its original value.
  -  images used for re-calibration: 
    - create 'experience' folder containing the images taken every ``SEC_TEST`` seconds and store into ./DATASET/img_data_XXX.
    - compile a training dataset (./DATASET/Train) from the most recent experience folders (img_data_XXX),
         using a random selection of images from previous folders combined with synthetic data.

<pre>
    1st training                               2nd training                             3rd training                             4th training
      |---|----------------------------------------|----------------------------------------|----------------------------------------|----------------------------------------...
   img_data_000         img_data_001                             img_data_002                              img_data_003         
                                           Train with 000-001                       Train with 000-002                       Train with 000-003 

</pre>

## Instructions for usage

- **Configuration**: Ensure the configuration.ini file is properly configured. Comments regarding the parameters are included within the file. The default parameters have been successfully tested.
- **Initial training**: The first training phase requires capturing images WITHOUT animals or other objects in the field of view. Make sure no animals, 
   people, or foreign objects are present during the initial minutes of camera operation. During this time, the camera collects its initial training dataset, and the captured images will be 
   classified as 'Blank'. If any animals, people, or objects not part of the natural background are detected during this period, the camera's AI functionality may not operate correctly.
  - If the camera is usually placed in the same location and you wish to bypass the initial training, you can comment out the lines starting with ``# 1) Create dataset:`` in ./scripts/service_app/Launch_service.sh. 
    By doing so, the camera will only re-train after the CALIB_PERIOD has been exceeded and when calibration is deemed necessary.
- **Functionality check**. After the initial training is complete, you can verify that the camera is functioning by ensuring that the LED turns ON when motion is detected around the camera.
- **Data retrieval**. Upon completion of operation, the main data and logs generated by the camera will be available in the ./OUTPUT folder.

 
                                              